model_list:
  - model_name: gemini-1.5-flash-1
    litellm_params: # Specifies the model name, help LiteLLM to route to the correct model + provider logic on the backend.
      model: gemini/gemini-1.5-flash
      api_key: os.environ/GEMINI_API_KEY
      rpm: 1                            # support load balancing or usage-based routing, not applyed for rate limit
  - model_name: gemini-1.5-flash-2
    litellm_params:
      model: gemini/gemini-1.5-flash
      api_key: os.environ/GEMINI_API_KEY
      rpm: 2
  - model_name: llama3
    litellm_params:
      model: "ollama/llama3:latest"
      api_base: "http://ollama:11434"
      api_key: "NA"
  - model_name: deepseek-v3.1
    litellm_params:
      model: openrouter/deepseek-v3.1
      api_base: https://openrouter.ai/api/v1/chat/completions
      api_key: os.environ/DEEPSEEK_API_KEY
  - model_name: deepseek-chat
    litellm_params:
      model: deepseek/deepseek-chat:free
      api_base: https://openrouter.ai/api/v1/chat/completions
      api_key: os.environ/DEEPSEEK_API_KEY_2


litellm_settings:
  set_verbose: true 
  callbacks: custom_callbacks.proxy_handler_instance
  drop_params: True


general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY   # Virtual key cho client gọi vào Proxy
  # database_url: os.environ/DATABASE_URL
  # port: os.environ/PORT
  # store_model_in_db: os.environ/STORE_MODEL_IN_DB

  # pass_through_endpoints:
  #   - path: "/v1/text-to-image"                        # Route expose ra từ LiteLLM
  #     target: "https://engine.prod.bria-api.com/v1/text-to-image/base/2.3"
  #     headers:
  #       Authorization: "Bearer os.environ/BRIA_API_KEY"   # Đọc key từ biến môi trường
  #       content-type: application/json
  #       accept: application/json
  #     forward_headers: true

  custom_auth: custom_auth.user_api_key_auth_auto_mode
  custom_auth_settings:
    mode: "auto" # can be 'on', 'off', 'auto' - 'auto' checks both litellm api key auth + custom auth